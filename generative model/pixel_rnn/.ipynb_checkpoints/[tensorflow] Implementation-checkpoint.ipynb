{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.initializers.GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inputs, num_outputs,\n",
    "          kernel_shape, # [kernel_height, kernel_stride]\n",
    "          mask_type, # A = position of current pixel, B = from next of curr pixel to end of image\n",
    "          strides=[1, 1], # [column_wise, row_wise]\n",
    "          padding = 'SAME',\n",
    "          activation_fn = None,\n",
    "          weights_initializaer = tf.initializers.GlorotUniform(), # tf.contrib.layers.xavier_initializer(),\n",
    "          weights_regularizer=None,\n",
    "          biases_initializer=tf.zeros_initializer,\n",
    "          biases_regularizer=None,\n",
    "          scope='conv2d'):\n",
    "    \n",
    "    batch_size, height, width, channel = inputs.get_shape().as_list()\n",
    "    kernel_h, kernel_w = kernel_shape\n",
    "    stride_h, stride_w = strides\n",
    "    \n",
    "    center_h = kernel_h // 2\n",
    "    center_w = kernel_w // 2\n",
    "    \n",
    "    weights_shape = [kernel_h, kernel_w, channel, num_outputs]\n",
    "    weights = tf.get_variable(\"weights\", weights_shape, \n",
    "                              tf.float32, weights_initializer, weights_regularizer)\n",
    "    \n",
    "    if mask_type is not None:\n",
    "        mask = np.ones((kernel_h, kernel_w, channel, num_outputs), dtype=np.float32)\n",
    "\n",
    "        mask[center_h, center_w+1: ,: ,:] = 0.\n",
    "        mask[center_h+1:, :, :, :] = 0.\n",
    "\n",
    "    if mask_type == 'a':\n",
    "        mask[center_h,center_w,:,:] = 0.\n",
    "\n",
    "    weights *= tf.constant(mask, dtype=tf.float32)\n",
    "    tf.add_to_collection('conv2d_weights_%s' % mask_type, weights)\n",
    "    \n",
    "    outputs = tf.nn.conv2d(inputs, \n",
    "                           weights, [1, stride_h, stride_w, 1], padding=padding, name='outputs')\n",
    "    tf.add_to_collection('conv2d_outputs', outputs)\n",
    "\n",
    "    if biases_initializer != None:\n",
    "        biases = tf.get_variable(\"biases\", [num_outputs,], \n",
    "                                 tf.float32, biases_initializer, biases_regularizer)\n",
    "        outputs = tf.nn.bias_add(outputs, biases, name='outputs_plus_b')\n",
    "\n",
    "    if activation_fn:\n",
    "        outputs = activation_fn(outputs, name='outputs_with_fn')\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelRNN(height, width, channel, params):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    height, width, channel - the dimensions of the input\n",
    "    params the hyperparameters of the network\n",
    "    \"\"\"\n",
    "    input_shape = [None, height, width, channel]\n",
    "    inputs = tf.placeholder(tf.float32, input_shape)\n",
    "    \n",
    "# ============================논문에서 제시된 모든 모델의 도입부====================\n",
    "\n",
    "    # input of main recurrent layers\n",
    "    scope = \"conv_inputs\"\n",
    "    conv_inputs = conv2d(inputs, params.hidden_dims, [7, 7], \"A\", scope=scope)\n",
    "                                # params.hidden_dims -> 128\n",
    "# ===========================================================================\n",
    "    \n",
    "    # main recurrent layers\n",
    "    last_hid = conv_inputs\n",
    "    for idx in xrange(params.recurrent_length):\n",
    "        scope = 'CONV%d' % idx\n",
    "        last_hid = conv2d(last_hid, 3, [1, 1], \"B\", scope=scope)\n",
    "        print(\"Building %s\" % scope)\n",
    "        \n",
    "        \n",
    "    # output recurrent layers\n",
    "    for idx in xrange(params.out_recurrent_length):\n",
    "        scope = 'CONV_OUT%d' % idx\n",
    "        last_hid = tf.nn.relu(conv2d(last_hid, params.out_hidden_dims, [1, 1], \"B\", scope=scope))\n",
    "                                            # params.out_hidden_dims -> 64\n",
    "        print(\"Building %s\" % scope)\n",
    "        \n",
    "        \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(conv2d_out_logits, inputs, name='loss'))\n",
    "\n",
    "    optimizer = tf.train.RMSPropOptimizer(p.learning_rate)\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "    new_grads_and_vars = \\\n",
    "        [(tf.clip_by_value(gv[0], -p.grad_clip, p.grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "    optim = optimizer.apply_gradients(new_grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv2d_out_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c04ab4a8b8c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2d_out_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSPropOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv2d_out_logits' is not defined"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(conv2d_out_logits, inputs, name='loss'))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(p.learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "new_grads_and_vars = \\\n",
    "    [(tf.clip_by_value(gv[0], -p.grad_clip, p.grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "optim = optimizer.apply_gradients(new_grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, images, inputs, output):\n",
    "    return sess.run(output, {inputs: images})\n",
    "\n",
    "def generate(sess, height, width, inputs, output):\n",
    "    samples = np.zeros((100, height, width, 1), dtype='float32')\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            next_sample = binarize(predict(sess, samples, inputs, output))\n",
    "            samples[:, i, j] = next_sample[:, i, j]\n",
    "\n",
    "    return samples\n",
    "\n",
    "def generate_occlusions(sess, height, width, inputs, output):\n",
    "    samples = occlude(images, height, width)\n",
    "    starting_position = [0,height//2]\n",
    "    for i in range(starting_position[1], height):\n",
    "        for j in range(starting_position[0], width):\n",
    "            next_sample = binarize(predict(sess, samples, inputs, output))\n",
    "            samples[:, i, j] = next_sample[:, i, j]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor2.3",
   "language": "python",
   "name": "tensor2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
